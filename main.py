# main.py

import os
import time
import threading
from pynput import keyboard as kb

from transcriber.recorder import Recorder
from transcriber.whisper import load_asr_model, transcribe_with_faster_whisper
from llms.llm import load_llm_client
from prompts.templates import get_corporate_summary_prompt, get_interview_prompt

from rag.embedder import Embedder
from rag.search import search
from prompts.templates import get_rag_answer_prompt
import faiss, json, os

# =========================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
# =========================
from utils.config import get_config

# –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
config = get_config()  # –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ "production" –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (—É–º–µ–Ω—å—à–∞–µ–º latency)
asr_model = load_asr_model(device=config["asr_device"])
llm_client = load_llm_client(host=config["llm_host"], model=config["llm_model"])
recorder = Recorder.create_auto(
    monitor_name=config["virtual_cable_name"],
    samplerate=config["sample_rate"],
    channels=config["channels"]
)

# –°–æ—Å—Ç–æ—è–Ω–∏—è (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –≤ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ)
is_meeting_active = False
is_question_active = False
pressed_keys = set()

# =========================
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ö–æ—Ç–∫–µ–µ–≤
# =========================
def handle_meeting_recording():
    """
    Ctrl+R:
    - –µ—Å–ª–∏ –Ω–µ –ø–∏—à–µ–º ‚Üí —Å—Ç–∞—Ä—Ç –∑–∞–ø–∏—Å–∏ –≤—Å—Ç—Ä–µ—á–∏ (audio/meetings/*.wav)
    - –µ—Å–ª–∏ –ø–∏—à–µ–º ‚Üí —Å—Ç–æ–ø, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (transcripts/meetings/*.txt), —Å–∞–º–º–∞—Ä–∏ ‚Üí summaries/*.json
    """
    global is_meeting_active

    if not is_meeting_active:
        # –°—Ç–∞—Ä—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∏ –≤—Å—Ç—Ä–µ—á–∏
        recorder.start_main_recording()
        print("‚ñ∂Ô∏è –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–ø–∏—Å—å –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞—á–∞—Ç–∞ (Ctrl+R —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å)")
        is_meeting_active = True
        return

    # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤—Å—Ç—Ä–µ—á–∏
    audio_path = recorder.stop_main_recording()
    print("‚èπ –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∫–∞...")

    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–µ–º (—Ñ—É–Ω–∫—Ü–∏—è —Å–∞–º–∞ –ø–æ–ª–æ–∂–∏—Ç —Ç–µ–∫—Å—Ç –≤ transcripts/meetings/*.txt)
    transcript_text = transcribe_with_faster_whisper(audio_path, asr_model=asr_model)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å–∞–º–º–∞—Ä–∏ –∏ –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM (–Ω–µ–ø–æ—Ç–æ–∫–æ–≤–æ ‚Äî —ç—Ç–æ –∫—Ä–∞—Ç–∫–∏–π JSON)
    prompt = get_corporate_summary_prompt(transcript_text)
    summary_json_str = llm_client.generate_answer(prompt)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º–º–∞—Ä–∏ –≤ summaries/
    os.makedirs("summaries", exist_ok=True)
    base = os.path.splitext(os.path.basename(audio_path))[0]  # meeting_...
    out_path = f"summaries/{base}_summary.json"
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(summary_json_str)
    print(f"‚úÖ –°–∞–º–º–∞—Ä–∏ –≤—Å—Ç—Ä–µ—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")

    is_meeting_active = False


def handle_question_recording():
    """
    Ctrl+Q:
    - –µ—Å–ª–∏ –Ω–µ –ø–∏—à–µ–º –≤–æ–ø—Ä–æ—Å ‚Üí —Å—Ç–∞—Ä—Ç (audio/questions/*.wav)
    - –µ—Å–ª–∏ –ø–∏—à–µ–º ‚Üí —Å—Ç–æ–ø, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (transcripts/questions/*.txt), –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM
    """
    global is_question_active

    if not is_question_active:
        # –ó–∞—â–∏—Ç–∞: –≤–æ–ø—Ä–æ—Å –ø–∏—à–µ–º —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ä–µ–º—è –≤—Å—Ç—Ä–µ—á–∏ (–ø–æ —Ç–≤–æ–µ–π –ª–æ–≥–∏–∫–µ)
        if not is_meeting_active:
            print("–û—à–∏–±–∫–∞: –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–ø–∏—Å—å –Ω–µ –∏–¥—ë—Ç. –ù–µ–ª—å–∑—è —Å—Ç–∞—Ä—Ç–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å.")
            return

        recorder.start_question_recording()
        print("üî¥ –ó–∞–ø–∏—Å—å –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞—á–∞—Ç–∞ (Ctrl+Q —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å)")
        is_question_active = True
        return

    # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤–æ–ø—Ä–æ—Å–∞
    audio_path = recorder.stop_question_recording()
    print("üîµ –ó–∞–ø–∏—Å—å –≤–æ–ø—Ä–æ—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∫–∞...")

    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–µ–º (—Ñ—É–Ω–∫—Ü–∏—è —Å–∞–º–∞ –ø–æ–ª–æ–∂–∏—Ç —Ç–µ–∫—Å—Ç –≤ transcripts/questions/*.txt)
    question_text = transcribe_with_faster_whisper(audio_path, asr_model=asr_model)
    print(f"–í–æ–ø—Ä–æ—Å: {question_text}")

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é-–æ—Ç–≤–µ—Ç–∞
    prompt = get_interview_prompt(question_text)

    # –¢–∞–π–º–µ—Ä + –ø–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    start_time = time.perf_counter()
    for chunk in llm_client.generate_answer_stream(prompt):
        print(chunk, end='', flush=True)
    print()  # –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –ø–æ—Ç–æ–∫–∞
    elapsed = time.perf_counter() - start_time
    print(f"‚è±Ô∏è –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∑–∞ {elapsed:.2f} —Å–µ–∫.")

    is_question_active = False


# =========================
# –õ–∏—Å—Ç–µ–Ω–µ—Ä —Ö–æ—Ç–∫–µ–µ–≤ (pynput)
# =========================
def on_press(key):
    pressed_keys.add(key)

    # Ctrl+R ‚Äî —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø –≤—Å—Ç—Ä–µ—á–∏
    if (kb.Key.ctrl_l in pressed_keys or kb.Key.ctrl_r in pressed_keys) and hasattr(key, 'char') and key.char in ('r', 'R'):
        threading.Thread(target=handle_meeting_recording, daemon=True).start()

    # Ctrl+Q ‚Äî —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø –≤–æ–ø—Ä–æ—Å–∞
    if (kb.Key.ctrl_l in pressed_keys or kb.Key.ctrl_r in pressed_keys) and hasattr(key, 'char') and key.char in ('q', 'Q'):
        threading.Thread(target=handle_question_recording, daemon=True).start()

    # ESC ‚Äî –≤—ã—Ö–æ–¥
    if key == kb.Key.esc:
        print("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return False  # –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å listener


def on_release(key):
    if key in pressed_keys:
        pressed_keys.remove(key)


def listen_hotkeys():
    print("====================================")
    print("Ctrl+R ‚Äî —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø –∑–∞–ø–∏—Å–∏ –≤—Å–µ–π –≤—Å—Ç—Ä–µ—á–∏")
    print("Ctrl+Q ‚Äî —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø –∑–∞–ø–∏—Å–∏ –≤–æ–ø—Ä–æ—Å–∞")
    print("ESC    ‚Äî –≤—ã—Ö–æ–¥")
    print("====================================")
    with kb.Listener(on_press=on_press, on_release=on_release) as listener:
        listener.join()

# === RAG –ø–æ –°–ê–ú–ú–ê–†–ò ===
def run_rag_chat_summaries():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏ –º–µ—Ç–∞
    idx_path  = os.path.join("rag_store", "faiss.index")
    meta_path = os.path.join("rag_store", "meta.json")
    if not (os.path.exists(idx_path) and os.path.exists(meta_path)):
        print("[RAG] –ò–Ω–¥–µ–∫—Å –ø–æ —Å–∞–º–º–∞—Ä–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞: python -m rag.build")
        return
    index = faiss.read_index(idx_path)
    with open(meta_path, "r", encoding="utf-8") as f:
        metas = json.load(f)

    embedder = Embedder()

    print("\n[RAG] –ß–∞—Ç –ø–æ –°–ê–ú–ú–ê–†–ò. –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit'):")
    while True:
        q = input("?> ").strip()
        if not q:
            continue
        if q.lower() in ("exit", "quit"):
            print("[RAG] –í—ã—Ö–æ–¥.")
            break

        q_vec = embedder.encode([q])                 # (1, d)
        hits  = search(index, metas, q_vec, top_k=5, threshold=0.32)

        # –î–ª—è MVP –ø–æ–¥–º–µ—à–∞–µ–º —Å—Å—ã–ª–∫–∏/–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        lines = []
        for h in hits:
            p = h["meta"].get("path")
            doc_id = h["meta"].get("doc_id")
            chunk_id = h["meta"].get("chunk_id")
            lines.append(f"[summary:{doc_id}#chunk{chunk_id}] score={h['score']:.2f} | {p}")
        retrieved = "–ù–∞–π–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å–∞–º–º–∞—Ä–∏:\n" + ("\n".join(lines) if lines else "–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        prompt = get_rag_answer_prompt(q, retrieved)

        print("\n--- –û—Ç–≤–µ—Ç (stream) ---")
        for chunk in llm_client.generate_answer_stream(prompt):
            print(chunk, end="", flush=True)
        print("\n----------------------\n")


# # === RAG –ø–æ –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø–ú ===
# def run_rag_chat_transcripts():
#     idx_path  = os.path.join("rag_store_transcripts", "faiss.index")
#     meta_path = os.path.join("rag_store_transcripts", "meta.json")
#     if not (os.path.exists(idx_path) and os.path.exists(meta_path)):
#         print("[RAG] –ò–Ω–¥–µ–∫—Å –ø–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è–º –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞: python -m rag.build_transcripts")
#         return
#     index = faiss.read_index(idx_path)
#     with open(meta_path, "r", encoding="utf-8") as f:
#         metas = json.load(f)
#
#     embedder = Embedder()
#
#     print("\n[RAG-TX] –ß–∞—Ç –ø–æ –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø–ú. –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit'):")
#     while True:
#         q = input("?> ").strip()
#         if not q:
#             continue
#         if q.lower() in ("exit", "quit"):
#             print("[RAG-TX] –í—ã—Ö–æ–¥.")
#             break
#
#         q_vec = embedder.encode([q])
#         hits  = search(index, metas, q_vec, top_k=5, threshold=0.32)
#
#         lines = []
#         for h in hits:
#             p = h["meta"].get("path")
#             doc_id = h["meta"].get("doc_id")
#             chunk_id = h["meta"].get("chunk_id")
#             typ = h["meta"].get("type")
#             lines.append(f"[{typ}:{doc_id}#chunk{chunk_id}] score={h['score']:.2f} | {p}")
#         retrieved = "–ù–∞–π–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π:\n" + ("\n".join(lines) if lines else "–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
#
#         prompt = get_rag_answer_prompt(q, retrieved)
#
#         print("\n--- –û—Ç–≤–µ—Ç (stream) ---")
#         for chunk in llm_client.generate_answer_stream(prompt):
#             print(chunk, end="", flush=True)
#         print("\n----------------------\n")

if __name__ == "__main__":
    listen_hotkeys()

    run_rag_chat_summaries()

    run_rag_chat_transcripts()
